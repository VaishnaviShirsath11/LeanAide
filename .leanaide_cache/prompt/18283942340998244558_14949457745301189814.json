[["A lower-block-triangular matrix is invertible if its diagonal is. ",{"type":"{m : Type u_2} →\n  {n : Type u_3} →\n    {α : Type u_4} →\n      [inst : Fintype m] →\n        [inst_1 : Fintype n] →\n          [inst_2 : DecidableEq m] →\n            [inst_3 : DecidableEq n] →\n              [inst_4 : CommRing α] →\n                (A : Matrix m m α) →\n                  (C : Matrix n m α) →\n                    (D : Matrix n n α) →\n                      [inst_5 : Invertible A] → [inst_6 : Invertible D] → Invertible (Matrix.fromBlocks A 0 C D)","name":"Matrix.fromBlocksZero₁₂Invertible","isProp":false,"docString":"A lower-block-triangular matrix is invertible if its diagonal is. ","distance":0.1997171805120636911556886161633883602917194366455078125}],[" Given a Hermitian matrix `A`, there exists an invertible matrix `P` of orthonormal eigenvectors such that `P^*-1 * A * P` is a diagonal matrix with `A`'s eigenvalues on the diagonal.",{"type":"∀ {𝕜 : Type u_1} [inst : RCLike 𝕜] {n : Type u_2} [inst_1 : Fintype n] {A : Matrix n n 𝕜} [inst_2 : DecidableEq n]\n  (hA : A.IsHermitian),\n  hA.eigenvectorMatrixInv * A = Matrix.diagonal (RCLike.ofReal ∘ hA.eigenvalues) * hA.eigenvectorMatrixInv","name":"Matrix.IsHermitian.spectral_theorem","isProp":true,"docString":" Given a Hermitian matrix `A`, there exists an invertible matrix `P` of orthonormal eigenvectors such that `P^*-1 * A * P` is a diagonal matrix with `A`'s eigenvalues on the diagonal.","distance":0.2307828478361220181369617421296425163745880126953125}],["This theorem, often referred to as the Diagonalization theorem or the Spectral theorem for matrices, states that any Hermitian matrix can be diagonalized by a change of basis. More specifically, given a Hermitian matrix `A`, there exists an invertible matrix `P` (which is the inverse of the matrix constituted by the orthonormal eigenvectors of `A`), such that `P * A` equals the product of the diagonal matrix formed by the eigenvalues of `A` and `P`. This theorem is fundamental in linear algebra, as it provides a simple representation for Hermitian matrices that is easier to work with.",{"type":"∀ {𝕜 : Type u_1} [inst : RCLike 𝕜] {n : Type u_2} [inst_1 : Fintype n] {A : Matrix n n 𝕜} [inst_2 : DecidableEq n]\n  (hA : A.IsHermitian),\n  hA.eigenvectorMatrixInv * A = Matrix.diagonal (RCLike.ofReal ∘ hA.eigenvalues) * hA.eigenvectorMatrixInv","name":"Matrix.IsHermitian.spectral_theorem","isProp":true,"docString":"This theorem, often referred to as the Diagonalization theorem or the Spectral theorem for matrices, states that any Hermitian matrix can be diagonalized by a change of basis. More specifically, given a Hermitian matrix `A`, there exists an invertible matrix `P` (which is the inverse of the matrix constituted by the orthonormal eigenvectors of `A`), such that `P * A` equals the product of the diagonal matrix formed by the eigenvalues of `A` and `P`. This theorem is fundamental in linear algebra, as it provides a simple representation for Hermitian matrices that is easier to work with.","distance":0.2186285745009244052550201331541757099330425262451171875}],["Any matrix can be reduced to diagonal form by elementary operations. Formulated here on `Type 0`\nbecause we will make an induction using `Fin r`.\nSee `exists_list_transvec_mul_mul_list_transvec_eq_diagonal` for the general version (which follows\nfrom this one and reindexing). ",{"value":null,"type":"∀ {𝕜 : Type u_3} [inst : Field 𝕜] (n : Type) [inst_1 : Fintype n] [inst_2 : DecidableEq n] (M : Matrix n n 𝕜),   ∃ L L' D,     List.prod (List.map Matrix.TransvectionStruct.toMatrix L) * M *         List.prod (List.map Matrix.TransvectionStruct.toMatrix L') =       Matrix.diagonal D","statement":"theorem Matrix.Pivot.exists_list_transvec_mul_mul_list_transvec_eq_diagonal_aux :\n    ∀ {𝕜 : Type u_3} [inst : Field 𝕜] (n : Type) [inst_1 : Fintype n] [inst_2 : DecidableEq n] (M : Matrix n n 𝕜),\n      ∃ L L' D,\n        (List.map Matrix.TransvectionStruct.toMatrix L).prod * M *\n            (List.map Matrix.TransvectionStruct.toMatrix L').prod =\n          Matrix.diagonal D :=\n  by sorry","name":"Matrix.Pivot.exists_list_transvec_mul_mul_list_transvec_eq_diagonal_aux","isProp":true,"docString":"Any matrix can be reduced to diagonal form by elementary operations. Formulated here on `Type 0`\nbecause we will make an induction using `Fin r`.\nSee `exists_list_transvec_mul_mul_list_transvec_eq_diagonal` for the general version (which follows\nfrom this one and reindexing). ","description":"This theorem states that for any square matrix `M` with entries from a field `𝕜` and indices from a finite type `n` with decidable equality, there exist lists `L` and `L'` of transvection structures and a function `D` such that when `D` is used to form a diagonal matrix, and `L` and `L'` are used to form lists of matrices (by applying the `toMatrix` function to each transvection structure in `L` and `L'`, and then taking the product of each list of matrices), the product of the matrix formed from `L`, `M`, and the matrix formed from `L'` is equal to the diagonal matrix formed from `D`. Essentially, it states that any matrix can be reduced to a diagonal form using elementary row and column operations, as represented by the transvection structures. This statement is formulated specifically for `Type 0` because it will be used in an induction argument using `Fin r`. The general version of this theorem, which follows from this one and reindexing, is `exists_list_transvec_mul_mul_list_transvec_eq_diagonal`.","concise-description":" For any square matrix over a field with decidable equality and finite indices, there exist lists of transvection structures whose products with the matrix and its transpose, and the product of their diagonal matrices, are equal."}],["An upper-block-triangular matrix is invertible if its diagonal is. ",{"type":"{m : Type u_2} →\n  {n : Type u_3} →\n    {α : Type u_4} →\n      [inst : Fintype m] →\n        [inst_1 : Fintype n] →\n          [inst_2 : DecidableEq m] →\n            [inst_3 : DecidableEq n] →\n              [inst_4 : CommRing α] →\n                (A : Matrix m m α) →\n                  (B : Matrix m n α) →\n                    (D : Matrix n n α) →\n                      [inst_5 : Invertible A] → [inst_6 : Invertible D] → Invertible (Matrix.fromBlocks A B 0 D)","name":"Matrix.fromBlocksZero₂₁Invertible","isProp":false,"docString":"An upper-block-triangular matrix is invertible if its diagonal is. ","distance":0.2017183824002541647768538268792326562106609344482421875}],[" For matrices A, B, C, and D over a commutative ring, if square matrices A and D are of finite sizes m and n, respectively, and rectangular matrices B and C have compatible sizes, then the block matrix [A | B  | C] [T| D] is invertible if and only if D is invertible and the Schur complement A - B * D^(-1) * C is invertible.",{"type":"∀ {m : Type u_2} {n : Type u_3} {α : Type u_4} [inst : Fintype m] [inst_1 : Fintype n] [inst_2 : DecidableEq m]\n  [inst_3 : DecidableEq n] [inst_4 : CommRing α] {A : Matrix m m α} {B : Matrix m n α} {C : Matrix n m α}\n  {D : Matrix n n α} [inst_5 : Invertible D], IsUnit (A.fromBlocks B C D) ↔ IsUnit (A - B * ⅟D * C)","name":"Matrix.isUnit_fromBlocks_iff_of_invertible₂₂","isProp":true,"docString":" For matrices A, B, C, and D over a commutative ring, if square matrices A and D are of finite sizes m and n, respectively, and rectangular matrices B and C have compatible sizes, then the block matrix [A | B  | C] [T| D] is invertible if and only if D is invertible and the Schur complement A - B * D^(-1) * C is invertible.","distance":0.288725965445013332821844187492388300597667694091796875}],["This theorem states that for any square matrix `A` of order `n` with entries in a linearly ordered commutative ring `S`, if all off-diagonal entries of `A` are negative and the sum of the entries of each column is positive, then the determinant of `A` is not zero. In other words, such a matrix is invertible. The type `n` is assumed to be finite and equipped with a decidable equality relation.",{"type":"∀ {n : Type u_1} [inst : Fintype n] [inst_1 : DecidableEq n] {S : Type u_2} [inst_2 : LinearOrderedCommRing S]\n  {A : Matrix n n S}, (Pairwise fun i j => A i j < 0) → (∀ (j : n), 0 < Finset.univ.sum fun i => A i j) → A.det ≠ 0","name":"Matrix.det_ne_zero_of_sum_col_pos","isProp":true,"docString":"This theorem states that for any square matrix `A` of order `n` with entries in a linearly ordered commutative ring `S`, if all off-diagonal entries of `A` are negative and the sum of the entries of each column is positive, then the determinant of `A` is not zero. In other words, such a matrix is invertible. The type `n` is assumed to be finite and equipped with a decidable equality relation.","distance":0.26452699590095873904971313095302321016788482666015625}],["Any matrix can be reduced to diagonal form by elementary operations. ",{"value":null,"type":"∀ {n : Type u_1} {𝕜 : Type u_3} [inst : Field 𝕜] [inst_1 : DecidableEq n] [inst_2 : Fintype n] (M : Matrix n n 𝕜),   ∃ L L' D,     List.prod (List.map Matrix.TransvectionStruct.toMatrix L) * M *         List.prod (List.map Matrix.TransvectionStruct.toMatrix L') =       Matrix.diagonal D","statement":"theorem Matrix.Pivot.exists_list_transvec_mul_mul_list_transvec_eq_diagonal :\n    ∀ {n : Type u_1} {𝕜 : Type u_3} [inst : Field 𝕜] [inst_1 : DecidableEq n] [inst_2 : Fintype n] (M : Matrix n n 𝕜),\n      ∃ L L' D,\n        (List.map Matrix.TransvectionStruct.toMatrix L).prod * M *\n            (List.map Matrix.TransvectionStruct.toMatrix L').prod =\n          Matrix.diagonal D :=\n  by sorry","name":"Matrix.Pivot.exists_list_transvec_mul_mul_list_transvec_eq_diagonal","isProp":true,"docString":"Any matrix can be reduced to diagonal form by elementary operations. ","description":"This theorem states that for any matrix `M` over a field `𝕜`, where the field has decidable equality and finiteness property, there exist lists `L` and `L'` of transvection structures and a diagonal matrix `D` such that the product of the matrices corresponding to `L`, `M`, and the matrices corresponding to `L'` equals `D`. In other words, any matrix can be reduced to a diagonal form by a sequence of elementary row and column operations, which are represented by transvections. These operations do not change the determinant of the matrix.\n","concise-description":" Given a matrix M over a decidably equal and finite field, there exist lists L and L' of transvection structures such that M is equivalent to their product with a diagonal matrix."}],["A matrix is invertible if the conjugate transpose is invertible. ",{"type":"{n : Type u_2} →\n  {α : Type u_3} →\n    [inst : Fintype n] →\n      [inst_1 : DecidableEq n] →\n        [inst_2 : Semiring α] →\n          [inst_3 : StarRing α] → (A : Matrix n n α) → [inst_4 : Invertible (Matrix.conjTranspose A)] → Invertible A","name":"Matrix.invertibleOfInvertibleConjTranspose","isProp":false,"docString":"A matrix is invertible if the conjugate transpose is invertible. ","distance":0.2175834051349832820587693049674271605908870697021484375}],[" For any square matrix A over a commutative ring of finite type with decidable equality, the transpose of the adjugate of A is equal to the adjugate of the transpose of A. (In mathematical notation: adj(A)^T = adj(A^T))",{"type":"∀ {n : Type v} {α : Type w} [inst : DecidableEq n] [inst_1 : Fintype n] [inst_2 : CommRing α] (A : Matrix n n α),\n  A.adjugate.transpose = A.transpose.adjugate","name":"Matrix.adjugate_transpose","isProp":true,"docString":" For any square matrix A over a commutative ring of finite type with decidable equality, the transpose of the adjugate of A is equal to the adjugate of the transpose of A. (In mathematical notation: adj(A)^T = adj(A^T))","distance":0.289482134269179847141373329577618278563022613525390625}],["This theorem states the following principle for induction on invertible matrices using transvections: Given a certain property `P` and a matrix `M` with non-zero determinant over a field `𝕜`, if `P` holds for all invertible diagonal matrices with non-zero determinant, if `P` holds for all transvections, and if `P` is preserved under multiplication of invertible matrices with non-zero determinant, then `P` holds for `M`. In other words, this theorem provides a way to prove a property for all invertible matrices by showing it holds for simpler classes of matrices (diagonal matrices and transvections), and is preserved under multiplication. This theorem essentially formalizes the fact that invertible matrices can be generated by invertible diagonal matrices and transvections.",{"type":"∀ {n : Type u_1} {𝕜 : Type u_3} [inst : Field 𝕜] [inst_1 : DecidableEq n] [inst_2 : Fintype n] (P : Matrix n n 𝕜 → Prop)\n  (M : Matrix n n 𝕜),\n  M.det ≠ 0 →\n    (∀ (D : n → 𝕜), (Matrix.diagonal D).det ≠ 0 → P (Matrix.diagonal D)) →\n      (∀ (t : Matrix.TransvectionStruct n 𝕜), P t.toMatrix) →\n        (∀ (A B : Matrix n n 𝕜), A.det ≠ 0 → B.det ≠ 0 → P A → P B → P (A * B)) → P M","name":"Matrix.diagonal_transvection_induction_of_det_ne_zero","isProp":true,"docString":"This theorem states the following principle for induction on invertible matrices using transvections: Given a certain property `P` and a matrix `M` with non-zero determinant over a field `𝕜`, if `P` holds for all invertible diagonal matrices with non-zero determinant, if `P` holds for all transvections, and if `P` is preserved under multiplication of invertible matrices with non-zero determinant, then `P` holds for `M`. In other words, this theorem provides a way to prove a property for all invertible matrices by showing it holds for simpler classes of matrices (diagonal matrices and transvections), and is preserved under multiplication. This theorem essentially formalizes the fact that invertible matrices can be generated by invertible diagonal matrices and transvections.","distance":0.269474162863517052723949518622248433530330657958984375}],["`Matrix.IsDiag.diagonal_diag` as an iff. ",{"value":null,"type":"∀ {α : Type u_1} {n : Type u_4} [inst : Zero α] [inst_1 : DecidableEq n] (A : Matrix n n α),   Matrix.IsDiag A ↔ Matrix.diagonal (Matrix.diag A) = A","statement":"theorem Matrix.isDiag_iff_diagonal_diag :\n    ∀ {α : Type u_1} {n : Type u_4} [inst : Zero α] [inst_1 : DecidableEq n] (A : Matrix n n α),\n      A.IsDiag ↔ Matrix.diagonal A.diag = A :=\n  by sorry","name":"Matrix.isDiag_iff_diagonal_diag","isProp":true,"docString":"`Matrix.IsDiag.diagonal_diag` as an iff. ","description":"This theorem, `Matrix.isDiag_iff_diagonal_diag`, states that for any square matrix `A` with entries of type `α` (where `α` has an notion of zero) and indices of type `n` (where `n` has a decidable equality), `A` is a diagonal matrix if and only if `A` is equal to the matrix obtained by setting the diagonal entries of `A` according to the function `A.diag` and setting all other entries to zero. Here, `A.IsDiag` indicates that `A` is a diagonal matrix, and `Matrix.diagonal A.diag` constructs a matrix with the diagonal entries given by `A.diag` and other entries set to zero.","concise-description":" A square matrix `A` over a type `α` with decidable equality and indices `n` is diagonal if and only if it is equal to the matrix obtained by setting its diagonal entries to the values in `A.diag` and setting all other entries to zero."}],["The diagonal of a square matrix. ",{"type":"{n : Type u_3} → {α : Type v} → Matrix n n α → n → α","name":"Matrix.diag","isProp":false,"docString":"The diagonal of a square matrix. ","distance":0.2314586695906150348722718490535044111311435699462890625}],[" For any square matrix A and scalar r, the diagonal of the matrix r * A is equal to the scalar multiplication of r and the diagonal of A.",{"type":"∀ {n : Type u_3} {R : Type u_7} {α : Type v} [inst : SMul R α] (r : R) (A : Matrix n n α), (r • A).diag = r • A.diag","name":"Matrix.diag_smul","isProp":true,"docString":" For any square matrix A and scalar r, the diagonal of the matrix r * A is equal to the scalar multiplication of r and the diagonal of A.","distance":0.296980455518732033848294804556644521653652191162109375}],["This theorem states that for any positive definite matrix `S` over a ring `𝕜` with a characteristic of real or complex numbers, indexed by a well-ordered type `n`, the diagonal matrix `D` in the LDL decomposition of `S` can be obtained by conjugating `S` with the inverse of the lower triangular matrix `L` in the decomposition. The conjugation is done as `L⁻¹ * S * (L⁻¹)ᵀ`, where `L⁻¹` is the inverse of `L`, and `(L⁻¹)ᵀ` is its complex conjugate transpose. In other words, the diagonal of the LDL decomposition is equal to this conjugated product.",{"type":"∀ {𝕜 : Type u_1} [inst : RCLike 𝕜] {n : Type u_2} [inst_1 : LinearOrder n] [inst_2 : IsWellOrder n fun x x_1 => x < x_1]\n  [inst_3 : LocallyFiniteOrderBot n] {S : Matrix n n 𝕜} [inst_4 : Fintype n] (hS : S.PosDef),\n  LDL.diag hS = LDL.lowerInv hS * S * (LDL.lowerInv hS).conjTranspose","name":"LDL.diag_eq_lowerInv_conj","isProp":true,"docString":"This theorem states that for any positive definite matrix `S` over a ring `𝕜` with a characteristic of real or complex numbers, indexed by a well-ordered type `n`, the diagonal matrix `D` in the LDL decomposition of `S` can be obtained by conjugating `S` with the inverse of the lower triangular matrix `L` in the decomposition. The conjugation is done as `L⁻¹ * S * (L⁻¹)ᵀ`, where `L⁻¹` is the inverse of `L`, and `(L⁻¹)ᵀ` is its complex conjugate transpose. In other words, the diagonal of the LDL decomposition is equal to this conjugated product.","distance":0.2730908370794333794862041031592525541782379150390625}],["A diagonal matrix is positive semidefinite iff its diagonal entries are nonnegative. ",{"type":"∀ {n : Type u_2} {R : Type u_3} [inst : Fintype n] [inst_1 : CommRing R] [inst_2 : PartialOrder R]\n  [inst_3 : StarOrderedRing R] [inst_4 : DecidableEq n] {d : n → R},\n  Matrix.PosSemidef (Matrix.diagonal d) ↔ ∀ (i : n), 0 ≤ d i","name":"Matrix.posSemidef_diagonal_iff","isProp":true,"docString":"A diagonal matrix is positive semidefinite iff its diagonal entries are nonnegative. ","distance":0.2351170213266288444575735638863989152014255523681640625}],["If matrix A is left invertible, then its inverse equals its left inverse. ",{"type":"∀ {n : Type u'} {α : Type v} [inst : Fintype n] [inst_1 : DecidableEq n] [inst_2 : CommRing α] {A B : Matrix n n α},\n  B * A = 1 → A⁻¹ = B","name":"Matrix.inv_eq_left_inv","isProp":true,"docString":"If matrix A is left invertible, then its inverse equals its left inverse. ","distance":0.237628351201241816426090736058540642261505126953125}],["If matrix A is right invertible, then its inverse equals its right inverse. ",{"type":"∀ {n : Type u'} {α : Type v} [inst : Fintype n] [inst_1 : DecidableEq n] [inst_2 : CommRing α] {A B : Matrix n n α},\n  A * B = 1 → A⁻¹ = B","name":"Matrix.inv_eq_right_inv","isProp":true,"docString":"If matrix A is right invertible, then its inverse equals its right inverse. ","distance":0.2471915376074671211181765784203889779746532440185546875}],["The transpose of an invertible matrix is invertible. ",{"type":"{n : Type u_2} →\n  {α : Type u_3} →\n    [inst : Fintype n] →\n      [inst_1 : DecidableEq n] →\n        [inst_2 : CommSemiring α] → (A : Matrix n n α) → [inst_3 : Invertible A] → Invertible (Matrix.transpose A)","name":"Matrix.invertibleTranspose","isProp":false,"docString":"The transpose of an invertible matrix is invertible. ","distance":0.2485041868655350760786149066916550509631633758544921875}]]